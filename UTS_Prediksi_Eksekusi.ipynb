{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Template Skrip Untuk Eksekusi"
      ],
      "metadata": {
        "id": "1jWq_a4lrFB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Library"
      ],
      "metadata": {
        "id": "EMkryJ8-rP_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp2qej6xq9ep"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset"
      ],
      "metadata": {
        "id": "rkp8Yyp5rXl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnsRjsQ2TQ43",
        "outputId": "cb1359bb-e7aa-455f-91a2-21dee3778850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_data = pd.read_csv('/content/drive/MyDrive/dataset/analisis_prediktif/UTS/train_data.csv')\n",
        "df_test_data = pd.read_csv('/content/drive/MyDrive/dataset/analisis_prediktif/UTS/public_test_data.csv')"
      ],
      "metadata": {
        "id": "G4VG1LsVraNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Definisi Fungsi Prediksi"
      ],
      "metadata": {
        "id": "U3pkGmmMrijn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediksi(train_df, test_df):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Drop initial unnecessary columns\n",
        "    train_df.drop(columns=['street', 'city', 'yr_renovated'], axis=1, inplace=True)\n",
        "    test_df.drop(columns=['street', 'city', 'yr_renovated'], axis=1, inplace=True)\n",
        "\n",
        "    # Step 2: Fill zero values in 'price' column with the median\n",
        "    def fill_zero_with_median(df, column_name='price'):\n",
        "        median_value = df[df[column_name] != 0][column_name].median()\n",
        "        df[column_name] = df[column_name].replace(0, median_value)\n",
        "        return df\n",
        "\n",
        "    train_df = fill_zero_with_median(train_df, 'price')\n",
        "\n",
        "    # Step 3: Remove anomalies where both bathrooms and bedrooms are 0\n",
        "    def remove_anomalies(df):\n",
        "        df.drop(df[(df['bathrooms'] == 0) & (df['bedrooms'] == 0)].index, inplace=True)\n",
        "\n",
        "    remove_anomalies(train_df)\n",
        "\n",
        "    # Step 4: Add house_age feature\n",
        "    def house_age(df):\n",
        "        current_year = datetime.now().year\n",
        "        df['house_age'] = current_year - df['yr_built']\n",
        "        return df\n",
        "\n",
        "    train_df = house_age(train_df)\n",
        "    test_df = house_age(test_df)\n",
        "\n",
        "    # Step 5: Add lot_living_ratio feature\n",
        "    def add_lot_living_ratio(df, lot_column='sqft_lot', living_column='sqft_living'):\n",
        "        df['lot_living_ratio'] = df.apply(\n",
        "            lambda row: row[living_column] / row[lot_column] if row[lot_column] != 0 else None,\n",
        "            axis=1)\n",
        "        return df\n",
        "\n",
        "    train_df = add_lot_living_ratio(train_df)\n",
        "    test_df = add_lot_living_ratio(test_df)\n",
        "\n",
        "    # Step 6: Add quality_index feature\n",
        "    def add_quality_index_column(df):\n",
        "        df['quality_index'] = df['condition'] * df['view']\n",
        "        return df\n",
        "\n",
        "    train_df = add_quality_index_column(train_df)\n",
        "    test_df = add_quality_index_column(test_df)\n",
        "\n",
        "    # Step 7: One-hot encode the 'statezip' column and sync train and test sets\n",
        "    def one_hot_encoding_sync(train_data, test_data, column_name='statezip'):\n",
        "        encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "        train_encoded = encoder.fit_transform(train_data[[column_name]])\n",
        "        encoded_columns = encoder.get_feature_names_out([column_name])\n",
        "        train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_columns)\n",
        "        train_data = train_data.drop(columns=[column_name]).reset_index(drop=True)\n",
        "        train_data = train_data.join(train_encoded_df)\n",
        "\n",
        "        test_encoded = encoder.transform(test_data[[column_name]])\n",
        "        test_encoded_df = pd.DataFrame(test_encoded, columns=encoded_columns)\n",
        "        test_data = test_data.drop(columns=[column_name]).reset_index(drop=True)\n",
        "        test_data = test_data.join(test_encoded_df)\n",
        "\n",
        "        return train_data, test_data\n",
        "\n",
        "    train_df, test_df = one_hot_encoding_sync(train_df, test_df, 'statezip')\n",
        "\n",
        "    # Step 8: Adjust 'view' column by adding 1 to each value\n",
        "    def adjust_view_column(df, column_name='view'):\n",
        "        df[column_name] = df[column_name] + 1\n",
        "        return df\n",
        "\n",
        "    train_df = adjust_view_column(train_df, 'view')\n",
        "    test_df = adjust_view_column(test_df, 'view')\n",
        "\n",
        "    # Step 9: Drop columns as specified and split into X and y sets\n",
        "    train_df = train_df.drop(columns=['condition', 'sqft_living', 'yr_built'])\n",
        "    test_df = test_df.drop(columns=['condition', 'sqft_living', 'yr_built'])\n",
        "\n",
        "    X_train = train_df.drop(columns=['price'])\n",
        "    y_train = train_df['price']\n",
        "    X_test = test_df.drop(columns=['price'])\n",
        "    y_test = test_df['price']\n",
        "\n",
        "    model = XGBRegressor(random_state=0, n_estimators=178, learning_rate= 0.1589, max_depth=3)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Calculate execution time\n",
        "    time.sleep(3)  # Simulated delay\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    return {\"execution_time\": execution_time, \"RMSE\": rmse}"
      ],
      "metadata": {
        "id": "A322022wSt5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Jalankan"
      ],
      "metadata": {
        "id": "IOO2up49trby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vIu_H6wHxgVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediksi(df_train_data,df_test_data)"
      ],
      "metadata": {
        "id": "eQlGal8ltuTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fd8038-1b46-4247-98f6-72187770a663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'execution_time': 3.3209104537963867, 'RMSE': 176534.30426220005}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}